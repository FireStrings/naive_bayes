{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['rapidez da peste m√∫sica ednaldo pereira', 'musica'], ['god is good dance por ednaldo pereira', 'musica'], ['ednaldo pereira skate montagem por legal ednaldo pereira', 'musica'], ['ednaldo pereira vermelho brasil montagem por _foda ednaldo pereira', 'musica'], ['bandeira de f√£ ruiva montagem por ednaldo pereira', 'musica'], ['um bom modo de enfrentar a contamina√ß√£o pelo preconceito √© oferecer informa√ß√£o (via _ombudsman)', 'sociedade'], ['ednaldo pereira desenho pequeno legal por valeu ednaldo pereira', 'musica'], ['desenho ednaldo pereira beb√™ estranho por _is_onnn valeu ednaldo pereira', 'musica'], ['as hist√≥rias reveladas pelos documentos que a pol√≠cia secreta da alemanha oriental n√£o conseguiu destruir', 'sociedade'], ['cota√ß√£o usada passar√° a ser a do dia da compra e n√£o mais a do fechamento da fatura', 'economia'], ['nunca pensei em entrar na pol√≠tica tinha asco diz eduardo bolsonaro', 'politica'], ['indicadores de fevereiro ser√£o divulgados nesta semana', 'saude'], ['pms resgatam com vida rec√©m nascida de bueiro na zona norte de sp', 'sociedade'], ['metade dos brasileiros acredita que renda vai aumentar em 2020 diz banco leia na coluna painel s a de', 'economia'], ['cafeteria no abc paulista mistura caf√© com blues e oferece card√°pio extenso numa atmosfera especial', 'gastronomia'], ['ind√∫stria e congresso reagem e avisam governo que resistir√£o a corte unilateral de tarifa comum do mercosul', 'politica'], ['opini√£o moro enrubesce a falta de vergonha com declara√ß√µes sobre greve de pms no ce', 'politica'], ['rt com o companheiro sebasti√£o salgado hoje em paris tivemos uma boa conversa sobre a amaz√¥nia desenvolvimento sustent√°vel', 'politica'], ['ocde reduz previs√£o de crescimento mundial por efeito do coronav√≠rus', 'saude'], ['opini√£o para tomar lugar do chefe duce moro persegue at√© roqueiros e viola carta', 'politica'], ['linha 15 prata do metr√¥ de s√£o paulo ficar√° fechada hoje', 'sociedade'], ['guarda de seguran√ßa demitido mant√©m ref√©ns em shopping nas filipinas', 'sociedade'], ['segundo paciente de covid 19 no brasil √© funcion√°rio da xp investimentos', 'saude'], ['opini√£o censura a uma exposi√ß√£o de arte e o projeto pr√≥ estuprador da direita rea√ßa', 'politica'], ['divorciados reino unido e uni√£o europeia discutem a rela√ß√£o em clima quente', 'politica'], ['para governadores negar tropas para o cear√° seria motivo para impeachment de bolsonaro', 'politica'], ['m√°rcio fran√ßa recebe apoio do pdt na disputa pela prefeitura de sp', 'politica'], ['apoio nas ruas definir√° futuro do atrito de bolsonaro com congresso diz cientista pol√≠tica', 'politica'], ['maia participa de almo√ßo debate de grupo criado por doria', 'politica'], ['conselho tem 17 queixas contra deltan e a mais avan√ßada est√° com indicado por deputados', 'politica'], ['fragilidade de dilma temer e bolsonaro leva congresso a papel de protagonismo', 'politica'], ['bolsonaro congela acordo e espera apoio para manter vetos ao or√ßamento impositivo', 'politica'], ['o que a folha pensa hesita√ß√£o perigosa bolsonaro semeia inseguran√ßa ao indicar simpatias por pleitos de pms amotinados', 'politica'], ['ap√≥s sa√≠da de m√©dicos cubanos mortes de beb√™s ind√≠genas crescem 12% em 2019', 'saude'], ['opini√£o do josias de souza falta √† briga pelo or√ßamento o b√°sico pol√≠tica p√∫blica', 'economia'], ['quatro pessoas morreram centenas de casas ficaram alagadas e muitos moradores perderam tudo o que tinham devido √†s chuvas no rio', 'sociedade'], ['bruno diz que bola n√£o matou eliza e pede que macarr√£o conte a verdade', 'sociedade'], ['caf√© da manh√£ üîä rep√≥rter relata viagem por br 163 que leva soja de mato grosso a par√° ou√ßa', 'sociedade'], ['bom dia muitas escolas precisam rever suas prioridades n√©', 'sociedade'], ['o modelo tem sido chamado pelos cr√≠ticos de parlamentarismo branco (via _poder)', 'politica'], ['painel escola de elite de sp contraria minist√©rio da sa√∫de e coloca alunos em quarentena por coronav√≠rus (via )', 'saude'], ['rt tem algo muito errado quando uma deputada federal comemora a agress√£o contra uma colega em frente √† filha menor de idade', 'politica'], ['rt moscou tem inverno acima de 0 grau celsius pela primeira vez em 200 anos de medi√ß√µes napole√£o se revirando no t√∫mulo', 'sociedade'], ['acaba com o sus gente n√£o serve pra nada', 'saude'], ['madonna cancela mais um show da turn√™ madame x por les√£o no joelho', 'musica'], ['escritor foge dos cart√µes postais e v√™ tail√¢ndia a partir de transexuais em livro', 'arte'], ['tem programa√ß√£o nova na miriam leit√£o roberto d √°vila andr√©ia sadi gerson camarotti marcelo lins mario sergio conti heraldo pereira e cristiana l√¥bo est√£o agora em novo hor√°rio a partir das 23h de segunda a sexta grandes entrevistas grandes entrevistadores', 'arte'], ['silvio berlusconi tem novas cores e uma nova causa no futebol', 'esporte'], ['neste ano quem tem direito a restitui√ß√£o vai receber o dinheiro mais cedo', 'economia'], ['taleban diz que s√≥ dialoga com governo afeg√£o se prisioneiros forem soltos', 'politica'], ['rt hoje √© segunda sem carne', 'gastronomia'], ['sobe para 13 o n√∫mero de mortos em naufr√°gio no ap (via _cotidiano)', 'sociedade'], ['coronav√≠rus deve puxar economia global para n√≠vel mais baixo desde 2009 diz ocde', 'saude'], ['falha em pneus suspende circula√ß√£o de trens no monotrilho de sp nesta segunda (2)', 'sociedade'], ['hypera compra licen√ßa de rem√©dios que inclui dramin e neosaldina por us$ 825 mi', 'saude'], ['bbb 20 bianca acusa pyong de ass√©dio pede sua sa√≠da e diz que pode busc√° lo na porta da globo', 'entretenimento'], ['rt painel s a grupo de empres√°rios diz que n√£o vai a ato contra congresso', 'politica'], ['rt conselho tem 17 queixas contra deltan e a mais avan√ßada est√° com indicado por deputados _poder', 'politica'], ['entrevista o magistrado criou um sistema que garante que nenhum preso fique nenhum um dia a mais do que o necess√°rio na cadeia e defende que prender mais √© um erro por', 'politica'], ['ana maria braga volta ao mais voc√™ e diz que seu tumor j√° reduziu 50% a miss√£o √© a cura', 'sociedade'], ['saiba onde assistir aos jogos da copa libertadores de 2020', 'esporte'], ['o c√©u que nos oprime que inspirou o sat√≠rico jojo rabbit √© relato duro da segunda guerra', 'sociedade']]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "import re\n",
    "import sys\n",
    "\n",
    "\n",
    "def cleanText(tweet):\n",
    "    tweet = ' '.join(re.sub(\"(@[A-Za-z0-9]+)|(#[A-Za-z0-9]+)\", \" \", tweet).split())\n",
    "    tweet = ' '.join(re.sub(\"(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
    "    tweet = ' '.join(re.sub(\"[\\|\\.\\,\\\"\\'\\!\\?\\:\\;\\-\\=]\", \" \", tweet).split())\n",
    "    tweet = tweet.lower()\n",
    "    \n",
    "    return tweet\n",
    "\n",
    "\n",
    "df = pd.read_csv('data/data_tweeter.csv', sep=\";\")\n",
    "l = []\n",
    "for i,j in zip(df['texto'], df['class']):\n",
    "    t = cleanText(i)\n",
    "    l.append([t, j])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>_foda</th>\n",
       "      <th>_is_onnn</th>\n",
       "      <th>bandeira</th>\n",
       "      <th>beb√™</th>\n",
       "      <th>brasil</th>\n",
       "      <th>cancela</th>\n",
       "      <th>da</th>\n",
       "      <th>dance</th>\n",
       "      <th>de</th>\n",
       "      <th>desenho</th>\n",
       "      <th>...</th>\n",
       "      <th>peste</th>\n",
       "      <th>por</th>\n",
       "      <th>rapidez</th>\n",
       "      <th>ruiva</th>\n",
       "      <th>show</th>\n",
       "      <th>skate</th>\n",
       "      <th>turn√™</th>\n",
       "      <th>um</th>\n",
       "      <th>valeu</th>\n",
       "      <th>vermelho</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows √ó 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   _foda  _is_onnn  bandeira  beb√™  brasil  cancela  da  dance  de  desenho  \\\n",
       "0      0         0         0     0       0        0   1      0   0        0   \n",
       "1      0         0         0     0       0        0   0      1   0        0   \n",
       "2      0         0         0     0       0        0   0      0   0        0   \n",
       "3      1         0         0     0       1        0   0      0   0        0   \n",
       "4      0         0         1     0       0        0   0      0   1        0   \n",
       "5      0         0         0     0       0        0   0      0   0        1   \n",
       "6      0         1         0     1       0        0   0      0   0        1   \n",
       "7      0         0         0     0       0        1   1      0   0        0   \n",
       "\n",
       "   ...  peste  por  rapidez  ruiva  show  skate  turn√™  um  valeu  vermelho  \n",
       "0  ...      1    0        1      0     0      0      0   0      0         0  \n",
       "1  ...      0    1        0      0     0      0      0   0      0         0  \n",
       "2  ...      0    1        0      0     0      1      0   0      0         0  \n",
       "3  ...      0    1        0      0     0      0      0   0      0         1  \n",
       "4  ...      0    1        0      1     0      0      0   0      0         0  \n",
       "5  ...      0    1        0      0     0      0      0   0      1         0  \n",
       "6  ...      0    1        0      0     0      0      0   0      1         0  \n",
       "7  ...      0    1        0      0     1      0      1   1      0         0  \n",
       "\n",
       "[8 rows x 37 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['texto', 'class']\n",
    "rows = l\n",
    "\n",
    "# rows = [['This is my book', 'stmt'], \n",
    "#         ['They are novels', 'stmt'],\n",
    "#         ['have you read this book', 'question'],\n",
    "#         ['who is the author', 'question'],\n",
    "#         ['what are the characters', 'question'],\n",
    "#         ['This is how I bought the book', 'stmt'],\n",
    "#         ['I like fictions', 'stmt'],\n",
    "#         ['what is your favorite book', 'question']]\n",
    "\n",
    "training_data = pd.DataFrame(rows, columns=columns)\n",
    "\n",
    "\n",
    "\n",
    "#CountVect\n",
    "stmt_docs = [row['texto'] for index,row in training_data.iterrows() if row['class'] == 'politica']\n",
    "\n",
    "vec_s = CountVectorizer()\n",
    "X_s = vec_s.fit_transform(stmt_docs)\n",
    "tdm_s = pd.DataFrame(X_s.toarray(), columns=vec_s.get_feature_names())\n",
    "\n",
    "q_docs = [row['texto'] for index,row in training_data.iterrows() if row['class'] == 'musica']\n",
    "\n",
    "vec_q = CountVectorizer()\n",
    "X_q = vec_q.fit_transform(q_docs)\n",
    "tdm_q = pd.DataFrame(X_q.toarray(), columns=vec_q.get_feature_names())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Frequency\n",
    "word_list_s = vec_s.get_feature_names();    \n",
    "count_list_s = X_s.toarray().sum(axis=0) \n",
    "freq_s = dict(zip(word_list_s,count_list_s))\n",
    "\n",
    "word_list_q = vec_q.get_feature_names();    \n",
    "count_list_q = X_q.toarray().sum(axis=0) \n",
    "freq_q = dict(zip(word_list_q,count_list_q))\n",
    "\n",
    "#Prob\n",
    "prob_s = []\n",
    "for word, count in zip(word_list_s, count_list_s):\n",
    "    prob_s.append(count/len(word_list_s))\n",
    "\n",
    "probs = dict(zip(word_list_s, prob_s))\n",
    "\n",
    "prob_q = []\n",
    "for word, count in zip(word_list_q, count_list_q):\n",
    "    prob_q.append(count/len(word_list_q))\n",
    "    \n",
    "probq = dict(zip(word_list_q, prob_q))\n",
    "\n",
    "\n",
    "docs = [row['texto'] for index,row in training_data.iterrows()]\n",
    "\n",
    "vec = CountVectorizer()\n",
    "X = vec.fit_transform(docs)\n",
    "\n",
    "total_features = len(vec.get_feature_names())\n",
    "\n",
    "total_cnts_features_s = count_list_s.sum(axis=0)\n",
    "total_cnts_features_q = count_list_q.sum(axis=0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "new_sentence = 'Ednaldo'\n",
    "new_word_list = word_tokenize(new_sentence)\n",
    "\n",
    "prob_s_with_ls = []\n",
    "for word in new_word_list:\n",
    "    if word in freq_s.keys():\n",
    "        count = freq_s[word]\n",
    "    else:\n",
    "        count = 0\n",
    "    prob_s_with_ls.append((count + 1)/(total_cnts_features_s + total_features))\n",
    "    \n",
    "r_s = dict(zip(new_word_list,prob_s_with_ls))\n",
    "\n",
    "prob_q_with_ls = []\n",
    "for word in new_word_list:\n",
    "    if word in freq_q.keys():\n",
    "        count = freq_q[word]\n",
    "    else:\n",
    "        count = 0\n",
    "    prob_q_with_ls.append((count + 1)/(total_cnts_features_q + total_features))\n",
    "    \n",
    "r_q = dict(zip(new_word_list,prob_q_with_ls))\n",
    "\n",
    "print(r_q)\n",
    "\n",
    "# df.drop(['Unnamed: 0'], inplace=True, axis=1)\n",
    "\n",
    "\n",
    "# document = [\"This is the most beautiful place in the world.\", \"This man has more skills to show in cricket than any other game.\", \"Hi there! how was your ladakh trip last month?\", \"There was a player who had scored 200+ runs in single cricket innings in his career.\", \"I have got the opportunity to travel to Paris next year for my internship.\", \"May be he is better than you in batting but you are much better than him in bowling.\", \"That was really a great day for me when I was there at Lavasa for the whole night.\", \"That‚Äôs exactly I wanted to become, a highest ratting batsmen ever with top scores.\", \"Does it really matter wether you go to Thailand or Goa, its just you have spend your holidays.\", \"Why don‚Äôt you go to Switzerland next year for your 25th Wedding anniversary?\", \"Travel is fatal to prejudice, bigotry, and narrow mindedness., and many of our people need it sorely on these accounts.\", \"Stop worrying about the potholes in the road and enjoy the journey.\", \"No cricket team in the world depends on one or two players. The team always plays to win.\", \"Cricket is a team game. If you want fame for yourself, go play an individual game.\", \"Because in the end, you won‚Äôt remember the time you spent working in the office or mowing your lawn. Climb that goddamn mountain.\", \"Isn‚Äôt cricket supposed to be a team sport? I feel people should decide first whether cricket is a team game or an individual sport.\"]\n",
    "\n",
    "# document =  df['texto']\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "# from sklearn.cluster import KMeans\n",
    "\n",
    "# vectorizer = TfidfVectorizer(stop_words='english')\n",
    "# X = vectorizer.fit_transform(document)\n",
    "\n",
    "\n",
    "# true_k = 2\n",
    "# model = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1)\n",
    "# model.fit(X)\n",
    "\n",
    "# order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "# terms = vectorizer.get_feature_names()\n",
    "\n",
    "# for i in range(true_k):\n",
    "#     print(\"Cluster %d:\" % i),\n",
    "#     for ind in order_centroids[i, :10]:\n",
    "#         print(\" %s\" % terms[ind])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
